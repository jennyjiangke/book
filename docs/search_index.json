[["index.html", "Media Analytics With R Preface", " Media Analytics With R Jenny Jiang &amp; Brian Walsh 2022-08-19 Preface The rapid development of information technology, along with the emergence of big data in the field of digital media, projects a workforce shortage for data-driven positions. In particular, the ability to use statistics to analyze and interpret the data obtained from tracking user interactions on websites and social media platforms make Communications students stand out in competitive job markets from a variety of industries. However, the integration of analytics into universities’ communication programs and curricula (e.g., Journalism, Television and Cinema, Public Relations, Strategic Communications, Communication Design, Health Communication, Sports Communication, Environmental Communication) is yet to catch up to the industry’s new demands. To address this need, this book introduces Communication students to R, which is a free software environment for statistical computing and graphics, to measure and analyze audiences’ digital footprints, employ data-driven problem solving to gauge audience engagement, formulate insights, plan and execute strategies, and evaluate outcomes. "],["r-for-media-analytics.html", "Chapter 1 R for Media Analytics", " Chapter 1 R for Media Analytics "],["basic-statistics.html", "Chapter 2 Basic Statistics 2.1 Variables &amp; Levels of Measurement 2.2 Statistical Analyses of a Single Variable 2.3 # Text Analysis", " Chapter 2 Basic Statistics This chapter uses data from Google Analytics’ channels report, which demonstrates how much of traffic is coming from specific paid versus unpaid channels, as well as data from social listening of #BlackLivesMatter and #StopAsianHate on Twitter to illustrate not only descriptive statistics that describe the properties of sample and population data but also inferential statistics for testing hypotheses and drawing conclusions regarding the relationships between variables. Specifically, we are going to introduce the fundamentals of statistics that cover various aspects of analyzing a single variable, two variables, and three or more variables. Let’s import the Google Analytics’ channels report into RStudio. #You will need to install readxl package library(readxl) my_data &lt;- read_excel(&quot;google analytics sample data.xlsx&quot;) #Create a dataset and name it as my_data Table 2.1 presents parts of a public demo dataset of channels report from Google Analytics of Google Merchandise Store, which is an affiliate of the holding company, Google, and an e-commerce business site that deals with marketing and selling of Google, YouTube, and Android branded merchandise such as stationaries, bags among other products. #You will need to install kableExtra package library(kableExtra) knitr::kable(head(my_data[,1:12], 20), digits = 5, booktabs = TRUE, caption = &#39;The First 20 Rows of the Google Analytics Sample Data&#39; ) %&gt;% kable_styling(font_size = 6.5) Table 2.1: The First 20 Rows of the Google Analytics Sample Data Channel Age Users New Users Sessions Bounce Rate Pages / Session Avg. Session Duration Ecommerce Conversion Rate Transactions Revenue Year Direct 25-34 81822 76251 118241 0.42193 5.82467 227.6724 0.03649 4315 332771.829 2021 Direct 18-24 65506 61565 88898 0.47178 4.98222 199.7854 0.02642 2349 198848.060 2021 Direct 35-44 41947 38535 59313 0.42185 5.91531 229.8105 0.03842 2279 189792.736 2021 Direct 45-54 26800 24967 37477 0.44659 5.47669 226.9229 0.03421 1282 109531.822 2021 Direct 55-64 12981 12217 17703 0.46444 5.26922 213.1094 0.03474 615 54808.702 2021 Direct 65+ 9432 8849 12548 0.46788 5.23932 210.5902 0.02981 374 35609.855 2021 Paid Search 18-24 2015 1766 2797 0.55703 4.71505 175.1087 0.02252 63 8423.719 2021 Paid Search 35-44 1394 1216 1980 0.47525 5.20909 157.2596 0.03535 70 8175.394 2021 Paid Search 25-34 2175 1829 3198 0.43809 5.88149 195.8474 0.03502 112 7576.795 2021 Direct 25-34 30772 29628 40539 0.37803 5.78436 233.6450 0.00306 124 7240.313 2020 Direct 18-24 17545 17024 21888 0.42708 5.07753 210.2462 0.00315 69 5325.412 2020 Direct 45-54 8491 8126 11115 0.38570 5.73117 230.9463 0.00495 55 4173.602 2020 Paid Search 45-54 1083 960 1387 0.56669 4.39726 138.6871 0.02307 32 4086.483 2021 Direct 35-44 14088 13560 18461 0.38248 5.53648 226.3607 0.00444 82 3993.809 2020 Organic Search 25-34 35978 32853 47132 0.51390 3.97070 164.3456 0.00068 32 1738.469 2020 (Other) 35-44 284 174 523 0.24474 7.62524 278.2505 0.03824 20 1657.444 2021 Direct 55-64 4466 4287 5862 0.40242 5.46571 232.1102 0.00409 24 1530.108 2020 (Other) 25-34 3440 2370 4741 0.31533 5.90719 232.4685 0.00337 16 1472.471 2020 (Other) 18-24 500 302 849 0.34982 5.61602 244.2697 0.03651 31 1395.053 2021 Paid Search 55-64 804 748 1009 0.62537 3.59068 111.0684 0.01388 14 1315.551 2021 See the bibliography at the end of the chapter for referral to the complete dataset that you can access and work with. 2.1 Variables &amp; Levels of Measurement In a dataset, the columns identify the variables that represent certain qualities of individuals. Any quality that can vary can be considered a variable. Variables can take on different values or attributes. An attribute is a specific value on a variable. For example, gender might be a variable that we are interested in, and the attributes of gender could be male, female, transgender, and non-binary. We use levels of measurement to describe how precisely variables are recorded. There are four levels of measurement: nominal, ordinal, interval, and ratio representing the transition from analyzing qualitative to quantitative data. 2.1.1 Nominal Data Nominal data is used to label variables. Gender, nationality, race, and ethnicity are a few of the most common examples of nominal data. It can only be categorized based on qualitative differences and there are no orderings or directions among different categories. We only know that males and females have qualitative differences in terms of gender, but we cannot tell how much they differ, nor could we sort individuals based on their gender. We can still assign numbers to different attributes of nominal variables (e.g., we can assign 1 to females and 2 to males, or vice versa), but the numbers only serve as labels that lack numerical values. For the dataset of Google Analytics from Google Merchandise Store (Table 1), the variable Channel is measured at the nominal level, and it indicates the channel through which traffic got to Google Merchandise Store. Organic Search indicates visits from unpaid search results. Direct indicates visits where users navigated directly to the URL, or the source of the visit is unknown. Referral indicates traffic where users clicked a link from another site, excluding major search engines. Display indicates traffic from display advertising, such as Google AdWords remarketing campaigns. Social indicates visits from social networks (Facebook, Twitter, etc.). Paid Search indicates traffic from the PPC (Pay Per Click) campaigns run in search results. Since each variable should be exhaustive to include all the possibilities, for the variable of Channel, the attribute “Other” is assigned referring to traffic from an un-identified channel. All these different channels through which a user reaches our website are different attributes our channel variable can have. 2.1.2 Ordinal Data Ordinal data also can be categorized, but there are rankings or orderings or scaling between categories. The ordinal measurement has been widely used to analyze variables such as education level (e.g., “high school,” “BS,” “MS,” “Ph.D.”), income level (e.g., “less than 50K,” “50-100K,” “over 100K”), and socioeconomic status (e.g., “lower class,” “middle class,” and “upper class”). For the dataset of Google Analytics from Google Merchandise Store (Table 2.1), the variable Age is also ordinal, and it refers to the age group of the users. For such ordinal variable, we can turn it into quantitative by assigning numerical values to different categories. For example, Age can be defined as having six attributes:1 = 18-24; 2 = 25-34; 3 = 35-44; 4 = 45-54; 5 = 55-64; 6 = 65+. There is a logical ordering among the different age groups, in a way that whoever answers “6” is older than individuals who answer “5” to this question. However, we cannot precisely tell the differences between the two groups because each attribute covers a wide range, and the ranges of different attributes are of different sizes. 2.1.3 Interval Data Interval data refers not only to the classification and ordering of data but also specifies that the distances between every two adjacent attributes on a scale are equal. For interval data, the difference between two values is meaningful, but there is no true zero point or fixed beginning, which refers to a scale where 0 indicates the absence of something. The most popular example is the temperature in degrees Fahrenheit or Celsius. The difference between 90 degrees F and 80 degrees F is the same difference between 70 degrees F and 60 degrees F; however, when it comes to 0 degrees F, we cannot say that temperature no longer exists. For interval measures, the value 0 does not mean the absence of this variable; rather, it is just an arbitrary setting that we have agreed upon. Another example of interval data is year. For year, 0 does not represent the missing value but indicates the year when Christ was born, and the time before 0 is given the prefix BC. If you were born in the year of 2005 and I was born in the year of 2000, we know that I will be five years older than you. For the dataset of Google Analytics from Google Merchandise Store (Table 2.1), the only interval variable is Year, indicating the year of each observation. 2.1.4 Ratio Data For ratio data, the difference between two values is also meaningful, and it has a true zero, indicating the absence of such variable. Media consumption is a great example of ratio data. Media consumption can be measured in days, hours, or minutes a person exposes him/herself to media content. If a person has zero media consumption, that means this person does not consume media at all; in other words, to this person, media consumption is absent. For ratio data, zero is the starting point, and the distance between two adjacent values is the same. In addition, it makes sense to calculate the ratio of different values: If you have six hours of media consumption and I only have three hours, then we can say that you consume twice as much media as I do. Table 2.1 has six ratio variables. Sessions are the total number of sessions within the date range. A session is the period time a user is actively engaged with the website of Google Merchandise Store. Users are the number of users who have initiated at least one session during the date range, with the value of zero representing no such user exists. New Users are the number of first-time users during the selected date range. Transactions are the number of completed purchases on Google Merchandise Store. Ecommerce Conversion Rate refers to the E-commerce conversion rate that is the percentage of sessions that resulted in an e-commerce transaction. Revenue refers to the revenue of the completed purchases. If the revenue from the display channel is 0, that just means there is no income produced by the display Ads. What you can do to analyze your data may be limited due to the level of measurement of the variable. The complexity and precision of the level of measurement increase from nominal to ratio. For the ratio level of measurement, we can not only add numbers or subtract numbers but calculate the ratio of two numbers. For example, if the revenue from the organic search channel is 8k and from the paid search is 4k, then the revenue generated from organic search is twice as much as the revenue from paid search. The rows in a spreadsheet are closely associated with the unit of analysis, which is one of the most important ideas in a research project and the major entity that you are analyzing in your study. You will need to determine the unit of analysis since it determines the analysis you do for your research. For instance, if you are comparing the e-commerce performances (e.g., User, Sessions, Transactions, Revenues, ECR) of different channels, the unit of analysis is each individual channel. If you are comparing the e-commerce performance of different age groups, the unit of analysis is each age group. If you are comparing the e-commerce performance of different channels and age groups, the unit of analysis is each individual channel at each age group. 2.2 Statistical Analyses of a Single Variable After defining your research questions and the related unit(s) of analysis, and levels of measurement, we may start the data analysis journey by conducting a statistical analysis of a single variable. 2.2.1 Frequency Distribution The easiest thing we can do is to count the number of times an event or a value occurs for the variable(s) of our choice, and this is called Frequency analysis. We can aggregate individual observations of a variable into groups so that a frequency distribution of these groups can serve as a convenient means of summarizing or describing our data. We are going to use the dplyr package to count the aggregated transactions by channel and age groups. #Frequency and grouped frequency analysis #You will need to install dplyr package library(dplyr) Transaction_Frequency_Channel &lt;- my_data %&gt;% group_by(Channel) %&gt;% summarise(Frequency = sum(Transactions)) Transaction_Frequency_Age &lt;- my_data %&gt;% group_by(Age) %&gt;% summarise(Frequency = sum(Transactions)) Table 2.2 demonstrated the grouped frequency of transactions for each channel and age group. From the frequency analysis, we can tell that the direct channel (n = 11581) and the age group of 25 to 34 (n = 4654) had the greatest number of transactions in Google Merchandise Store. knitr::kable( list( head(arrange(Transaction_Frequency_Channel, desc(Frequency))), head(arrange(Transaction_Frequency_Age, desc(Frequency)))), booktabs = TRUE, caption = &#39;Grouped Transaction Frequency for Channel and Age&#39; ) %&gt;% kable_styling(font_size = 14) Table 2.2: Grouped Transaction Frequency for Channel and Age Channel Frequency Direct 11581 Paid Search 330 (Other) 138 Organic Search 98 Referral 32 Display 6 Age Frequency 25-34 4654 18-24 2558 35-44 2496 45-54 1394 55-64 673 65+ 414 2.2.2 Percentage Change Here, we can also use the grouped frequency analysis to compare the revenue from each channel between 2020 and 2021 to assess the dynamic changes of each channel. #Creat a subset for year 2020 and year 2021 my_data_2020 &lt;- my_data %&gt;% filter(Year == 2020) my_data_2021 &lt;- my_data %&gt;% filter(Year == 2021) Revenue_Frequency_2020 &lt;- my_data_2020 %&gt;% group_by(Channel) %&gt;% summarise(Revenue = sum(Revenue)) Revenue_Frequency_2021 &lt;- my_data_2021 %&gt;% group_by(Channel) %&gt;% summarise(Revenue = sum(Revenue)) As illustrated in Table 2.3, the direct channel created the most revenues in both 2020 and 2021. When you have such data for two points in time, you can calculate how much change there has been over this period. The result is expressed as a percentage in absolute numbers and is called the percentage change or the rate of change. Here is the formula: Percentage Change = [(Number at later time / Number at earlier time) - 1] × 100%. knitr::kable( list( head(arrange(Revenue_Frequency_2020, desc(Revenue))), head(arrange(Revenue_Frequency_2021, desc(Revenue)))), booktabs = TRUE, caption = &#39;Grouped Revenue in 2020 and 2021&#39; ) %&gt;% kable_styling(font_size = 14) Table 2.3: Grouped Revenue in 2020 and 2021 Channel Revenue Direct 23565.6812 Organic Search 4628.4410 (Other) 3154.8063 Paid Search 1975.9309 Referral 864.7263 Social 164.8144 Channel Revenue Direct 921363.0041 Paid Search 29908.1791 (Other) 5193.1180 Referral 852.0686 Display 354.3391 Organic Search 188.6451 For example, from Table 2.3, in 2020, the revenue generated from the paid search channel was $1975.93. And in 2020, the revenue generated from the paid search channel was 29908.18. The percentage change of revenue from the paid search channel from 2020 to 2021 is then calculated as follows: [(29908.18/ 1975.93)-1] x 100%= 1413.62%, meaning that from the year of 2020 to the year of 2021, the revenue generated from the paid search channel increased by 1413.62%. 2.2.3 Relative Frequency For the frequency analysis, we also can count how often something happens divided by all outcomes, which is called the relative frequency analysis. For example, from Table 3, the revenue from the organic search channel in 2020 is $4,628.44, and the total revenue in 2020 is the sum of revenue from all channels, which is $34422.26.The relative revenue from the organic search channel is 4,628.44/34422.26 = 13.44%, indicating 13.44% of the revenue in 2020 was from the organic search channel. We can use the codes below to get the relative revenue for each channel in 2020 and 2021 (Table 2.4). Revenue_Relative_Frequency_2020 &lt;- my_data_2020 %&gt;% group_by(Channel) %&gt;% summarise(&#39;Revenue_Percentage&#39; = sum(Revenue)/sum(my_data_2020$Revenue)) Revenue_Relative_Frequency_2021 &lt;- my_data_2021 %&gt;% group_by(Channel) %&gt;% summarise(&#39;Revenue_Percentage&#39; = sum(Revenue)/sum(my_data_2021$Revenue)) knitr::kable( list( head(arrange(Revenue_Relative_Frequency_2020, desc(Revenue_Percentage))), head(arrange(Revenue_Relative_Frequency_2021, desc(Revenue_Percentage)))), booktabs = TRUE, caption = &#39;Grouped Revenue in 2020 and 2021&#39; ) %&gt;% kable_styling(font_size = 14) Table 2.4: Grouped Revenue in 2020 and 2021 Channel Revenue_Percentage Direct 0.6846058 Organic Search 0.1344607 (Other) 0.0916502 Paid Search 0.0574027 Referral 0.0251211 Social 0.0047880 Channel Revenue_Percentage Direct 0.9618529 Paid Search 0.0312225 (Other) 0.0054213 Referral 0.0008895 Display 0.0003699 Organic Search 0.0001969 2.2.4 Percentage Points We can use the term “percentage points” to compare two different percentages at two points in time. The best way to explain this is through an example: from Table 2.4, in 2020, the share of revenue from the Paid Search channel was 5.74%. In 2021, the share of revenue from the Paid Search channel was 3.12%. The difference of these two percentages is calculated in percentage points: 3.12 % - 5.74 % = -2.62%. This means that the share of revenue from Paid Search channel in 2021 was almost three percentage points lower than the share of revenue from the Paid Search channel in 2020. 2.2.5 Rate In data analysis, some variables, such as the ECR (e-commerce conversion rate from Table 2.1), are too small to visualize. Under such circumstances, we can represent the percentage as rate by converting the small proportions to a whole number with one, two, or three digits on a base of some multiple of 1,000, 10,000, 100,000, or 1 million. For example, from Table 2.1, in 2020, the Ecommerce Conversion Rate of the organic search channel for users of 25 to 34 is 0.00068 or 0.068%. Instead of reporting the percentage, we can move the decimal place farther to the right, sufficient to make a number greater than 1, which allows us to better visualize the data. In the case of Ecommerce Conversion Rate, moving the decimal point four places to the right is the same as multiplying the value by 10,000. Consequently, the Ecommerce Conversion Rate of the organic search channel was 6.8 per 10,000 sessions. We can use the r code below to add a column representing the Ecommerce Conversion Rate per 10,000 sessions for my_data. my_data$ECR &lt;- my_data$`Ecommerce Conversion Rate`*10000 Now, the new column has been added to my_data as illustrated in Table 2.5. knitr::kable(head(my_data[,1:13], 20), digits = 5, booktabs = TRUE, caption = &#39;The First 20 Rows of the Google Analytics Sample Data&#39; ) %&gt;% kable_styling(font_size = 6.5) Table 2.5: The First 20 Rows of the Google Analytics Sample Data Channel Age Users New Users Sessions Bounce Rate Pages / Session Avg. Session Duration Ecommerce Conversion Rate Transactions Revenue Year ECR Direct 25-34 81822 76251 118241 0.42193 5.82467 227.6724 0.03649 4315 332771.829 2021 364.93264 Direct 18-24 65506 61565 88898 0.47178 4.98222 199.7854 0.02642 2349 198848.060 2021 264.23542 Direct 35-44 41947 38535 59313 0.42185 5.91531 229.8105 0.03842 2279 189792.736 2021 384.23280 Direct 45-54 26800 24967 37477 0.44659 5.47669 226.9229 0.03421 1282 109531.822 2021 342.07647 Direct 55-64 12981 12217 17703 0.46444 5.26922 213.1094 0.03474 615 54808.702 2021 347.39875 Direct 65+ 9432 8849 12548 0.46788 5.23932 210.5902 0.02981 374 35609.855 2021 298.05547 Paid Search 18-24 2015 1766 2797 0.55703 4.71505 175.1087 0.02252 63 8423.719 2021 225.24133 Paid Search 35-44 1394 1216 1980 0.47525 5.20909 157.2596 0.03535 70 8175.394 2021 353.53535 Paid Search 25-34 2175 1829 3198 0.43809 5.88149 195.8474 0.03502 112 7576.795 2021 350.21889 Direct 25-34 30772 29628 40539 0.37803 5.78436 233.6450 0.00306 124 7240.313 2020 30.58783 Direct 18-24 17545 17024 21888 0.42708 5.07753 210.2462 0.00315 69 5325.412 2020 31.52412 Direct 45-54 8491 8126 11115 0.38570 5.73117 230.9463 0.00495 55 4173.602 2020 49.48268 Paid Search 45-54 1083 960 1387 0.56669 4.39726 138.6871 0.02307 32 4086.483 2021 230.71377 Direct 35-44 14088 13560 18461 0.38248 5.53648 226.3607 0.00444 82 3993.809 2020 44.41796 Organic Search 25-34 35978 32853 47132 0.51390 3.97070 164.3456 0.00068 32 1738.469 2020 6.78944 (Other) 35-44 284 174 523 0.24474 7.62524 278.2505 0.03824 20 1657.444 2021 382.40918 Direct 55-64 4466 4287 5862 0.40242 5.46571 232.1102 0.00409 24 1530.108 2020 40.94166 (Other) 25-34 3440 2370 4741 0.31533 5.90719 232.4685 0.00337 16 1472.471 2020 33.74815 (Other) 18-24 500 302 849 0.34982 5.61602 244.2697 0.03651 31 1395.053 2021 365.13545 Paid Search 55-64 804 748 1009 0.62537 3.59068 111.0684 0.01388 14 1315.551 2021 138.75124 2.2.6 Ratio Ratio compares the size of two numbers indicating how many times one number contains another. For example, let’s calculate the ratio of returning users and new users using the formula: Number of Old Users / Number of New Users. We first use the r code below to create a new column old user (users - new users), then we use the group_by function to calculate the ratio fo returning users and new users for each channel. #creating a new colunme of old users my_data$OldUsers &lt;- my_data$Users-my_data$&#39;New Users&#39; userratio &lt;- my_data %&gt;% group_by(Channel) %&gt;% summarise(OldUsers = sum(OldUsers), NewUsers = sum(`New Users`),Ratio = sum(OldUsers)/sum(`New Users`)) From Table 2.6, we can find that besides the un-defined channel, the referral channel has a relatively higher ratio of returning (old) users to new users, indicating a better retention rate. knitr::kable( head(arrange(userratio, desc(Ratio))), booktabs = TRUE, caption = &#39;The Ratio of Old Users and New Users for Each Channel&#39; ) %&gt;% kable_styling(font_size = 14) Table 2.6: The Ratio of Old Users and New Users for Each Channel Channel OldUsers NewUsers Ratio (Other) 3383 7268 0.4654651 Referral 8101 23027 0.3518044 Paid Search 2116 11593 0.1825239 Affiliates 1002 8071 0.1241482 Organic Search 8428 81809 0.1030205 Display 524 7624 0.0687303 2.2.7 Central Tendency Besides using frequency analysis to summarize the distribution of a variable, we also can use the central tendency analysis to understand which attribute of a variable is most typical or representative of the variable distribution. Specifically, the central tendency analysis describes what the center of the data for a variable is. What do we mean by the center of the data? For many, the mean, median, and mode. Mean is the sum of all data points divided by the total number of observations. Median is the midpoint in data with an equal number of data points above and below. If the number of data points is even, then Median is the mean of the two midpoints. Mode is the data point that is most prevalent in the data set. It represents the most likely outcome in a data set. Let’s first create a small dataset of test scores from 20 students. StudentID &lt;- c(1:20) Score &lt;- c(40,50,50,60,60,60,60,60,70,70,70,80,80,80,80,90,90,90,90,100) TestData &lt;- data.frame(StudentID, Score) ScoreFrequency &lt;- as.data.frame(table(TestData$Score)) # Calculate the frequency of each score colnames(ScoreFrequency) &lt;- c(&quot;Score&quot;,&quot;Frequency&quot;) Table 2.7 demonstrates the frequency of each score. knitr::kable( head(arrange(ScoreFrequency)), booktabs = TRUE, caption = &#39;Frequency of Test Scores from 20 Students&#39;, align = &quot;l&quot; ) %&gt;% kable_styling(font_size = 16) Table 2.7: Frequency of Test Scores from 20 Students Score Frequency 40 1 50 2 60 5 70 3 80 4 90 4 The mean score is the sum of all scores divided by 20. The related formula is: (40x1 + 50x2 + 60x5 + 70x3 + 80x4 +90x4 + 100x1)/20 = 71.5, meaning that the average score among these 20 students is 71.5. When it comes to identifying the median value, we want to sort all individuals from the lowest value to the highest value, and whoever in the middle gives us the median value. But the problem is, we have 20 students in this sample, which is an even number, meaning that there will be two individuals in the middle (Table 2.8: student number 10 and number 11). For situations like this, we take the mean of these two individuals’ values to compute the median: (70+70)/2 = 70 (Table 2.8). knitr::kable(head(TestData, 20), booktabs = TRUE, caption = &#39;A Small Dataset of Test Scores from 20 Students&#39;, align = &quot;l&quot; ) %&gt;% kable_styling(font_size = 16) Table 2.8: A Small Dataset of Test Scores from 20 Students StudentID Score 1 40 2 50 3 50 4 60 5 60 6 60 7 60 8 60 9 70 10 70 11 70 12 80 13 80 14 80 15 80 16 90 17 90 18 90 19 90 20 100 We can easily identify the most frequent test score by looking into the score distribution visualization. # You will need install ggplot2 package library(ggplot2) # Barplot ggplot(ScoreFrequency, aes(x=Score, y=Frequency)) + geom_bar(stat = &quot;identity&quot;) Figure 2.1: Distribution of Test Scores from 20 Students Since 60 is the most frequent data point, it is the mode of the dataset. When we do the central tendency analysis, we also need to consider the data types. While interval and ratio data have a median, mode, and mean, the nominal data has only a mode. Furthermore, when the data distribution is symmetrical, such as your data is normally distributed, the mean is the best measure of central tendency. But, when the dataset has a strongly skewed distribution, the best indicator of central tendency is the median or mode, with the median usually preferred. Now we can use the code below to get the mean, median, and mode for the number of Users and New Users, number of Sessions, E-commerce Conversion Rates, Transactions, and Revenues for the Google analytics data of the Google Merchandise Store. #Calculate mean for each col mean_report &lt;- my_data %&gt;% summarise_if(is.numeric, mean) #Calculate median for each col median_report &lt;- my_data %&gt;% summarise_if(is.numeric, median) #Create the mode function getmode &lt;- function(v) { uniqv &lt;- unique(v) uniqv[which.max(tabulate(match(v, uniqv)))] } #Calculate mode for each col mode_report &lt;- my_data %&gt;% summarise_if(is.numeric, getmode) #combine the reports centerreport &lt;- as.data.frame(rbind(mean_report, median_report, mode_report)) rownames(centerreport) &lt;- c(&quot;Mean&quot;,&quot;Median&quot;,&quot;Mode&quot;) centerreport &lt;- centerreport[, -10] knitr::kable( head(arrange(centerreport)), booktabs = TRUE, caption = &#39;Descriptive Statistics-mean,median,mode&#39;, align = &quot;l&quot; ) %&gt;% kable_styling(font_size = 14) Table 2.9: Descriptive Statistics-mean,median,mode Users New Users Sessions Bounce Rate Pages / Session Avg. Session Duration Ecommerce Conversion Rate Transactions Revenue ECR OldUsers Mean 5661.279 5162.767 7707.93 0.4893791 4.868766 188.0428 0.0113537 141.7326 11538.6812 113.53744 498.5116 Median 940.500 768.500 1162.00 0.4757293 5.019697 193.5811 0.0022378 3.0000 131.0928 22.37833 116.5000 Mode 22.000 0.000 118241.00 0.4219349 5.824672 227.6724 0.0000000 0.0000 0.0000 0.00000 3412.0000 It is interesting to find the huge discrepancies between different central tendency measurements. This also indicates reporting results of different central tendency analyses can provide a more comprehensive understanding of the data distribution. For example, the mean value of Users (5661) is much higher than the median (940) and mode (22), indicating a skewed data distribution due to the existence of some large-value outliers. Weighted Mean is a special mean where some data points contribute more than others. To calculate the weighted mean, we need to consider the weight for each data point. For example, we can calculate the weighted mean of the E-commerce Conversion Rate by taking the number of users as weight. The more users each data point has, the larger weight for its E-commerce Conversion Rate (ECR). In R, we can use the function of weighted.mean as below to get the weighted mean of the ECR of the Google Store: #Calculated the weighted mean for ECR weighted.mean(my_data$`Ecommerce Conversion Rate`, my_data$Users) ## [1] 0.01783514 When taking the number of users into consideration, the weighted mean of the E-commerce Conversation Rate is almost 18 per 10,000 sessions, which is a bit higher than the normal mean, 11 per 10,000 sessions (Table above). This also indicates that the data points with high E-commerce Conversion Rates had more users than those with low rates. 2.2.8 Data Variation If two data sets have the same center points, does that mean they have the same data distribution? Let’s look at two small datasets: Score1 &lt;- data.frame(c(110, 90,70,50,30)) Score2 &lt;- data.frame(c(75, 70,70,70,65)) colnames(Score1) &lt;- c(&quot;Score1&quot;) colnames(Score2) &lt;- c(&quot;Score2&quot;) knitr::kable( list( head(arrange(Score1, desc(Score1))), head(arrange(Score2, desc(Score2)))), booktabs = TRUE, caption = &#39;Two Small Data Sets with the Same Mean and Median&#39; ) %&gt;% kable_styling(font_size = 14) Table 2.10: Two Small Data Sets with the Same Mean and Median Score1 110 90 70 50 30 Score2 75 70 70 70 65 Although they have the same mean (70) and median (70), the detailed data distributions vary significantly in a way that indicates the data in data set 1 were more spread out. This indicates that the mere central tendency measures cannot 100% accurately represent distribution. While the central tendency is the key to data description and prediction, variation is used to evaluate the quality of central tendency measures, and it plays an essential role in explaining statistical contribution. Variation Ratio reflects the proportion of cases that are not in the mode category. For example, from Table 8, the mode for Session is 3787. But this mode contains only two cases. Since the number of observations is 96, The variation ratio for Session is: (96-2)/96 = .98 or 98%, indicating the mode of 3787 is not a very representative indicator of sessions. To the contrary, for the variable of Transaction, the mode was 0 with 53 data points taking this value. The variation ratio of transaction is: (96-53)/96 = .45 or 45%, indicating “0” demonstrated relatively strong representativeness of transaction. This variation ratio also reflects the need for improvements of conversions for a variety of channels for the Google Merchandise Store. Range The worth of the median as a measure of central tendency is dependent on how narrowly scores are dispersed in the distribution. The range is the difference between the highest and lowest scores of a distribution. In our dataset, the range in class sizes is 237-17=220. As you can see, any ex treme score in a distribution, commonly referred to as an outlier, will greatly af fect the range. That much sensitivity is not desirable. Inter-ranges A more stable set of measures, called inter-ranges, drop off a specified highest and lowest percentage of the cases. The most popular are the inter-decile range, inter-quintile range, and inter-quartile range. Deciles are tenths, quintiles are fifths, and quartiles are fourths. These inter-ranges drop off the highest and lowest 10%, 20% and 25% of the cases, respectively, and then calculate the range of the remaining cases. For example, the inter-quartile range for class size in our small dataset would drop off the highest one-fourth and lowest one-fourth of the 23 cases. Since onefourth of 23 is not an even number (23/4=5.75), we’ll round up and drop off the top six (237, 133, 124, 103, 97, 90) and bottom six cases (17, 19, 19, 22, 23, 25). Of the remaining scores, the range is 56 (83-27). It is proper to say, then, that the range of the middle 50% of the cases is 56. The median score, 40 in this case, remains, of course, at the center of these mid dle 50% of the cases. sd 2.2.9 Case Study 2.3 # Text Analysis title: “An Introduction to Stringr” author: “Brian Walsh” date: ‘2022-06-21’ output: html_document: code_folding: show — Stringr is a package in the tidyverse that deals with, well, strings. What are strings? Anything in your data frame that is text- or character-based. So, in the case of babynames, that’d be Name and Sex - Year, Prop and N are not strings. Stringr allows for string manipulation across your entire dataset. If, for instance, we had a column of character data that repeatedly mis-spelled a name: Bryan instead of Brian, say - stringr could change every instance of Bryan into Brian in one line of code. Let’s start playing around with stringr by creating a variable that is equal to a string: library(stringr) sentence &lt;- c(&quot;hello&quot;, &quot;this is a long sentence&quot;, NA) Here are some functions from the stringr package that we can use to manipulate this sentence. How many characters are there in the string? str_length(sentence) ## [1] 5 23 NA Let’s replace every instance of ‘l’ with ‘x’ str_replace(sentence, &quot;l&quot;, &quot;X&quot;) ## [1] &quot;heXlo&quot; &quot;this is a Xong sentence&quot; NA Okay, now let’s create a new string that is a list of character strings: list &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) Let’s use str_sub to ‘pull out’ the first character of the string: str_sub(list, 1,1) ## [1] &quot;A&quot; &quot;B&quot; &quot;P&quot; What just happened? We told R to only grab the first character. Can we grab the first three characters? str_sub(list, 1,3) ## [1] &quot;App&quot; &quot;Ban&quot; &quot;Pea&quot; Let’s adjust the string’s content so each fruit is written entirely in lower case: str_to_lower(str_sub(list)) ## [1] &quot;apple&quot; &quot;banana&quot; &quot;pear&quot; We can also use stringr to detect specific words or phrases: str_detect(list, &quot;Pear&quot;) ## [1] FALSE FALSE TRUE R returns the position of “Pear” in the list. 2.3.1 Practical Applications of Stringr Let’s apply more Stringr concepts to a body of text. Where could we find text? How would we get text into R? One way would be a ‘web scrape’ - programmatically grabbing all the relevant text off of a page, or a series of pages - think Amazon product reviews. Another would be to import a body of text, like a .txt file, into R, and then break it up into individual words - more on this in the next chapter. A third way would be to use data included in an R package. More commonly, packages give you access to online datasets too large to download (Spotify, The New York Times, etc.). This technique, of selectively downloading relevant data from a much larger, online database, is the basis for the concept of an ‘API.’ [Application Programming Interface, if you’re wondering.] Many websites also use APIs, with downloadable files for analysis. So as to avoid any complication, let’s hold off on accessing an API until we cover Twitter, and continue to use the babynames dataset for now; then we can move on to analyzing lyrics, political speeches, and great works of literature. A snippet of Base R here, rather than the tidyverse: if we want to specify a column in our dataset, we write the name of the dataset or variable, then the dollar sign, then the name of the column: babynames$name ## [1] &quot;Mary&quot; &quot;Anna&quot; &quot;Emma&quot; &quot;Elizabeth&quot; &quot;Minnie&quot; &quot;Margaret&quot; ## [7] &quot;Ida&quot; &quot;Alice&quot; &quot;Bertha&quot; &quot;Sarah&quot; &quot;Annie&quot; &quot;Clara&quot; ## [13] &quot;Ella&quot; &quot;Florence&quot; &quot;Cora&quot; &quot;Martha&quot; &quot;Laura&quot; &quot;Nellie&quot; ## [19] &quot;Grace&quot; &quot;Carrie&quot; &quot;Maude&quot; &quot;Mabel&quot; &quot;Bessie&quot; &quot;Jennie&quot; ## [25] &quot;Gertrude&quot; &quot;Julia&quot; &quot;Hattie&quot; &quot;Edith&quot; &quot;Mattie&quot; &quot;Rose&quot; ## [31] &quot;Catherine&quot; &quot;Lillian&quot; &quot;Ada&quot; &quot;Lillie&quot; &quot;Helen&quot; &quot;Jessie&quot; ## [37] &quot;Louise&quot; &quot;Ethel&quot; &quot;Lula&quot; &quot;Myrtle&quot; &quot;Eva&quot; &quot;Frances&quot; ## [43] &quot;Lena&quot; &quot;Lucy&quot; &quot;Edna&quot; &quot;Maggie&quot; &quot;Pearl&quot; &quot;Daisy&quot; ## [49] &quot;Fannie&quot; &quot;Josephine&quot; &quot;Dora&quot; &quot;Rosa&quot; &quot;Katherine&quot; &quot;Agnes&quot; ## [55] &quot;Marie&quot; &quot;Nora&quot; &quot;May&quot; &quot;Mamie&quot; &quot;Blanche&quot; &quot;Stella&quot; ## [61] &quot;Ellen&quot; &quot;Nancy&quot; &quot;Effie&quot; &quot;Sallie&quot; &quot;Nettie&quot; &quot;Della&quot; ## [67] &quot;Lizzie&quot; &quot;Flora&quot; &quot;Susie&quot; &quot;Maud&quot; &quot;Mae&quot; &quot;Etta&quot; ## [73] &quot;Harriet&quot; &quot;Sadie&quot; &quot;Caroline&quot; &quot;Katie&quot; &quot;Lydia&quot; &quot;Elsie&quot; ## [79] &quot;Kate&quot; &quot;Susan&quot; &quot;Mollie&quot; &quot;Alma&quot; &quot;Addie&quot; &quot;Georgia&quot; ## [85] &quot;Eliza&quot; &quot;Lulu&quot; &quot;Nannie&quot; &quot;Lottie&quot; &quot;Amanda&quot; &quot;Belle&quot; ## [91] &quot;Charlotte&quot; &quot;Rebecca&quot; &quot;Ruth&quot; &quot;Viola&quot; &quot;Olive&quot; &quot;Amelia&quot; ## [97] &quot;Hannah&quot; &quot;Jane&quot; &quot;Virginia&quot; &quot;Emily&quot; &quot;Matilda&quot; &quot;Irene&quot; ## [103] &quot;Kathryn&quot; &quot;Esther&quot; &quot;Willie&quot; &quot;Henrietta&quot; &quot;Ollie&quot; &quot;Amy&quot; ## [109] &quot;Rachel&quot; &quot;Sara&quot; &quot;Estella&quot; &quot;Theresa&quot; &quot;Augusta&quot; &quot;Ora&quot; ## [115] &quot;Pauline&quot; &quot;Josie&quot; &quot;Lola&quot; &quot;Sophia&quot; &quot;Leona&quot; &quot;Anne&quot; ## [121] &quot;Mildred&quot; &quot;Ann&quot; &quot;Beulah&quot; &quot;Callie&quot; &quot;Lou&quot; &quot;Delia&quot; ## [127] &quot;Eleanor&quot; &quot;Barbara&quot; &quot;Iva&quot; &quot;Louisa&quot; &quot;Maria&quot; &quot;Mayme&quot; ## [133] &quot;Evelyn&quot; &quot;Estelle&quot; &quot;Nina&quot; &quot;Betty&quot; &quot;Marion&quot; &quot;Bettie&quot; ## [139] &quot;Dorothy&quot; &quot;Luella&quot; &quot;Inez&quot; &quot;Lela&quot; &quot;Rosie&quot; &quot;Allie&quot; ## [145] &quot;Millie&quot; &quot;Janie&quot; &quot;Cornelia&quot; &quot;Victoria&quot; &quot;Ruby&quot; &quot;Winifred&quot; ## [151] &quot;Alta&quot; &quot;Celia&quot; &quot;Christine&quot; &quot;Beatrice&quot; &quot;Birdie&quot; &quot;Harriett&quot; ## [157] &quot;Mable&quot; &quot;Myra&quot; &quot;Sophie&quot; &quot;Tillie&quot; &quot;Isabel&quot; &quot;Sylvia&quot; ## [163] &quot;Carolyn&quot; &quot;Isabelle&quot; &quot;Leila&quot; &quot;Sally&quot; &quot;Ina&quot; &quot;Essie&quot; ## [169] &quot;Bertie&quot; &quot;Nell&quot; &quot;Alberta&quot; &quot;Katharine&quot; &quot;Lora&quot; &quot;Rena&quot; ## [175] &quot;Mina&quot; &quot;Rhoda&quot; &quot;Mathilda&quot; &quot;Abbie&quot; &quot;Eula&quot; &quot;Dollie&quot; ## [181] &quot;Hettie&quot; &quot;Eunice&quot; &quot;Fanny&quot; &quot;Ola&quot; &quot;Lenora&quot; &quot;Adelaide&quot; ## [187] &quot;Christina&quot; &quot;Lelia&quot; &quot;Nelle&quot; &quot;Sue&quot; &quot;Johanna&quot; &quot;Lilly&quot; ## [193] &quot;Lucinda&quot; &quot;Minerva&quot; &quot;Lettie&quot; &quot;Roxie&quot; &quot;Cynthia&quot; &quot;Helena&quot; ## [199] &quot;Hilda&quot; &quot;Hulda&quot; &quot;Bernice&quot; &quot;Genevieve&quot; &quot;Jean&quot; &quot;Cordelia&quot; ## [205] &quot;Marian&quot; &quot;Francis&quot; &quot;Jeanette&quot; &quot;Adeline&quot; &quot;Gussie&quot; &quot;Leah&quot; ## [211] &quot;Lois&quot; &quot;Lura&quot; &quot;Mittie&quot; &quot;Hallie&quot; &quot;Isabella&quot; &quot;Olga&quot; ## [217] &quot;Phoebe&quot; &quot;Teresa&quot; &quot;Hester&quot; &quot;Lida&quot; &quot;Lina&quot; &quot;Winnie&quot; ## [223] &quot;Claudia&quot; &quot;Marguerite&quot; &quot;Vera&quot; &quot;Cecelia&quot; &quot;Bess&quot; &quot;Emilie&quot; ## [229] &quot;John&quot; &quot;Rosetta&quot; &quot;Verna&quot; &quot;Myrtie&quot; &quot;Cecilia&quot; &quot;Elva&quot; ## [235] &quot;Olivia&quot; &quot;Ophelia&quot; &quot;Georgie&quot; &quot;Elnora&quot; &quot;Violet&quot; &quot;Adele&quot; ## [241] &quot;Lily&quot; &quot;Linnie&quot; &quot;Loretta&quot; &quot;Madge&quot; &quot;Polly&quot; &quot;Virgie&quot; ## [247] &quot;Eugenia&quot; &quot;Lucile&quot; &quot;Lucille&quot; &quot;Mabelle&quot; &quot;Rosalie&quot; &quot;Kittie&quot; ## [253] &quot;Meta&quot; &quot;Angie&quot; &quot;Dessie&quot; &quot;Georgiana&quot; &quot;Lila&quot; &quot;Regina&quot; ## [259] &quot;Selma&quot; &quot;Wilhelmina&quot; &quot;Bridget&quot; &quot;Lilla&quot; &quot;Malinda&quot; &quot;Vina&quot; ## [265] &quot;Freda&quot; &quot;Gertie&quot; &quot;Jeannette&quot; &quot;Louella&quot; &quot;Mandy&quot; &quot;Roberta&quot; ## [271] &quot;Cassie&quot; &quot;Corinne&quot; &quot;Ivy&quot; &quot;Melissa&quot; &quot;Lyda&quot; &quot;Naomi&quot; ## [277] &quot;Norma&quot; &quot;Bell&quot; &quot;Margie&quot; &quot;Nona&quot; &quot;Zella&quot; &quot;Dovie&quot; ## [283] &quot;Elvira&quot; &quot;Erma&quot; &quot;Irma&quot; &quot;Leota&quot; &quot;William&quot; &quot;Artie&quot; ## [289] &quot;Blanch&quot; &quot;Charity&quot; &quot;Lorena&quot; &quot;Lucretia&quot; &quot;Orpha&quot; &quot;Alvina&quot; ## [295] &quot;Annette&quot; &quot;Catharine&quot; &quot;Elma&quot; &quot;Geneva&quot; &quot;Janet&quot; &quot;Lee&quot; ## [301] &quot;Leora&quot; &quot;Lona&quot; &quot;Miriam&quot; &quot;Zora&quot; &quot;Linda&quot; &quot;Octavia&quot; ## [307] &quot;Sudie&quot; &quot;Zula&quot; &quot;Adella&quot; &quot;Alpha&quot; &quot;Frieda&quot; &quot;George&quot; ## [313] &quot;Joanna&quot; &quot;Leonora&quot; &quot;Priscilla&quot; &quot;Tennie&quot; &quot;Angeline&quot; &quot;Docia&quot; ## [319] &quot;Ettie&quot; &quot;Flossie&quot; &quot;Hanna&quot; &quot;Letha&quot; &quot;Minta&quot; &quot;Retta&quot; ## [325] &quot;Rosella&quot; &quot;Adah&quot; &quot;Berta&quot; &quot;Elisabeth&quot; &quot;Elise&quot; &quot;Goldie&quot; ## [331] &quot;Leola&quot; &quot;Margret&quot; &quot;Adaline&quot; &quot;Floy&quot; &quot;Idella&quot; &quot;Juanita&quot; ## [337] &quot;Lenna&quot; &quot;Lucie&quot; &quot;Missouri&quot; &quot;Nola&quot; &quot;Zoe&quot; &quot;Eda&quot; ## [343] &quot;Isabell&quot; &quot;James&quot; &quot;Julie&quot; &quot;Letitia&quot; &quot;Madeline&quot; &quot;Malissa&quot; ## [349] &quot;Mariah&quot; &quot;Pattie&quot; &quot;Vivian&quot; &quot;Almeda&quot; &quot;Aurelia&quot; &quot;Claire&quot; ## [355] &quot;Dolly&quot; &quot;Hazel&quot; &quot;Jannie&quot; &quot;Kathleen&quot; &quot;Kathrine&quot; &quot;Lavinia&quot; ## [361] &quot;Marietta&quot; &quot;Melvina&quot; &quot;Ona&quot; &quot;Pinkie&quot; &quot;Samantha&quot; &quot;Susanna&quot; ## [367] &quot;Chloe&quot; &quot;Donnie&quot; &quot;Elsa&quot; &quot;Gladys&quot; &quot;Matie&quot; &quot;Pearle&quot; ## [373] &quot;Vesta&quot; &quot;Vinnie&quot; &quot;Antoinette&quot; &quot;Clementine&quot; &quot;Edythe&quot; &quot;Harriette&quot; ## [379] &quot;Libbie&quot; &quot;Lilian&quot; &quot;Lue&quot; &quot;Lutie&quot; &quot;Magdalena&quot; &quot;Meda&quot; ## [385] &quot;Rita&quot; &quot;Tena&quot; &quot;Zelma&quot; &quot;Adelia&quot; &quot;Annetta&quot; &quot;Antonia&quot; ## [391] &quot;Dona&quot; &quot;Elizebeth&quot; &quot;Georgianna&quot; &quot;Gracie&quot; &quot;Iona&quot; &quot;Lessie&quot; ## [397] &quot;Leta&quot; &quot;Liza&quot; &quot;Mertie&quot; &quot;Molly&quot; &quot;Neva&quot; &quot;Oma&quot; ## [403] &quot;Alida&quot; &quot;Alva&quot; &quot;Cecile&quot; &quot;Cleo&quot; &quot;Donna&quot; &quot;Ellie&quot; ## [409] &quot;Ernestine&quot; &quot;Evie&quot; &quot;Frankie&quot; &quot;Helene&quot; &quot;Minna&quot; &quot;Myrta&quot; ## [415] &quot;Prudence&quot; &quot;Queen&quot; &quot;Rilla&quot; &quot;Savannah&quot; &quot;Tessie&quot; &quot;Tina&quot; ## [421] &quot;Agatha&quot; &quot;America&quot; &quot;Anita&quot; &quot;Arminta&quot; &quot;Dorothea&quot; &quot;Ira&quot; ## [427] &quot;Luvenia&quot; &quot;Marjorie&quot; &quot;Maybelle&quot; &quot;Mellie&quot; &quot;Nan&quot; &quot;Pearlie&quot; ## [433] &quot;Sidney&quot; &quot;Velma&quot; &quot;Clare&quot; &quot;Constance&quot; &quot;Dixie&quot; &quot;Ila&quot; ## [439] &quot;Iola&quot; &quot;Jimmie&quot; &quot;Louvenia&quot; &quot;Lucia&quot; &quot;Ludie&quot; &quot;Luna&quot; ## [445] &quot;Metta&quot; &quot;Patsy&quot; &quot;Phebe&quot; &quot;Sophronia&quot; &quot;Adda&quot; &quot;Avis&quot; ## [451] &quot;Betsy&quot; &quot;Bonnie&quot; &quot;Cecil&quot; &quot;Cordie&quot; &quot;Emmaline&quot; &quot;Ethelyn&quot; ## [457] &quot;Hortense&quot; &quot;June&quot; &quot;Louie&quot; &quot;Lovie&quot; &quot;Marcella&quot; &quot;Melinda&quot; ## [463] &quot;Mona&quot; &quot;Odessa&quot; &quot;Veronica&quot; &quot;Aimee&quot; &quot;Annabel&quot; &quot;Ava&quot; ## [469] &quot;Bella&quot; &quot;Carolina&quot; &quot;Cathrine&quot; &quot;Christena&quot; &quot;Clyde&quot; &quot;Dena&quot; ## [475] &quot;Dolores&quot; &quot;Eleanore&quot; &quot;Elmira&quot; &quot;Fay&quot; &quot;Frank&quot; &quot;Jenny&quot; ## [481] &quot;Kizzie&quot; &quot;Lonnie&quot; &quot;Loula&quot; &quot;Magdalene&quot; &quot;Mettie&quot; &quot;Mintie&quot; ## [487] &quot;Peggy&quot; &quot;Reba&quot; &quot;Serena&quot; &quot;Vida&quot; &quot;Zada&quot; &quot;Abigail&quot; ## [493] &quot;Celestine&quot; &quot;Celina&quot; &quot;Claudie&quot; &quot;Clemmie&quot; &quot;Connie&quot; &quot;Daisie&quot; ## [499] &quot;Deborah&quot; &quot;Dessa&quot; &quot;Easter&quot; &quot;Eddie&quot; &quot;Emelia&quot; &quot;Emmie&quot; ## [505] &quot;Imogene&quot; &quot;India&quot; &quot;Jeanne&quot; &quot;Joan&quot; &quot;Lenore&quot; &quot;Liddie&quot; ## [511] &quot;Lotta&quot; &quot;Mame&quot; &quot;Nevada&quot; &quot;Rachael&quot; &quot;Robert&quot; &quot;Sina&quot; ## [517] &quot;Willa&quot; &quot;Aline&quot; &quot;Beryl&quot; &quot;Charles&quot; &quot;Daisey&quot; &quot;Dorcas&quot; ## [523] &quot;Edmonia&quot; &quot;Effa&quot; &quot;Eldora&quot; &quot;Eloise&quot; &quot;Emmer&quot; &quot;Era&quot; ## [529] &quot;Gena&quot; &quot;Henry&quot; &quot;Iris&quot; &quot;Izora&quot; &quot;Lennie&quot; &quot;Lissie&quot; ## [535] &quot;Mallie&quot; &quot;Malvina&quot; &quot;Mathilde&quot; &quot;Mazie&quot; &quot;Queenie&quot; &quot;Rosina&quot; ## [541] &quot;Salome&quot; &quot;Theodora&quot; &quot;Therese&quot; &quot;Vena&quot; &quot;Wanda&quot; &quot;Wilda&quot; ## [547] &quot;Altha&quot; &quot;Anastasia&quot; &quot;Besse&quot; &quot;Bird&quot; &quot;Birtie&quot; &quot;Clarissa&quot; ## [553] &quot;Claude&quot; &quot;Delilah&quot; &quot;Diana&quot; &quot;Emelie&quot; &quot;Erna&quot; &quot;Fern&quot; ## [559] &quot;Florida&quot; &quot;Frona&quot; &quot;Hilma&quot; &quot;Joseph&quot; &quot;Juliet&quot; &quot;Leonie&quot; ## [565] &quot;Lugenia&quot; &quot;Mammie&quot; &quot;Manda&quot; &quot;Manerva&quot; &quot;Manie&quot; &quot;Nella&quot; ## [571] &quot;Paulina&quot; &quot;Philomena&quot; &quot;Rae&quot; &quot;Selina&quot; &quot;Sena&quot; &quot;Theodosia&quot; ## [577] &quot;Tommie&quot; &quot;Una&quot; &quot;Vernie&quot; &quot;Adela&quot; &quot;Althea&quot; &quot;Amalia&quot; ## [583] &quot;Amber&quot; &quot;Angelina&quot; &quot;Annabelle&quot; &quot;Anner&quot; &quot;Arie&quot; &quot;Clarice&quot; ## [589] &quot;Corda&quot; &quot;Corrie&quot; &quot;Dell&quot; &quot;Dellar&quot; &quot;Donie&quot; &quot;Doris&quot; ## [595] &quot;Elda&quot; &quot;Elinor&quot; &quot;Emeline&quot; &quot;Emilia&quot; &quot;Esta&quot; &quot;Estell&quot; ## [601] &quot;Etha&quot; &quot;Fred&quot; &quot;Hope&quot; &quot;Indiana&quot; &quot;Ione&quot; &quot;Jettie&quot; ## [607] &quot;Johnnie&quot; &quot;Josiephine&quot; &quot;Kitty&quot; &quot;Lavina&quot; &quot;Leda&quot; &quot;Letta&quot; ## [613] &quot;Mahala&quot; &quot;Marcia&quot; &quot;Margarette&quot; &quot;Maudie&quot; &quot;Maye&quot; &quot;Norah&quot; ## [619] &quot;Oda&quot; &quot;Patty&quot; &quot;Paula&quot; &quot;Permelia&quot; &quot;Rosalia&quot; &quot;Roxanna&quot; ## [625] &quot;Sula&quot; &quot;Vada&quot; &quot;Winnifred&quot; &quot;Adline&quot; &quot;Almira&quot; &quot;Alvena&quot; ## [631] &quot;Arizona&quot; &quot;Becky&quot; &quot;Bennie&quot; &quot;Bernadette&quot; &quot;Camille&quot; &quot;Cordia&quot; ## [637] &quot;Corine&quot; &quot;Dicie&quot; &quot;Dove&quot; &quot;Drusilla&quot; &quot;Elena&quot; &quot;Elenora&quot; ## [643] &quot;Elmina&quot; &quot;Ethyl&quot; &quot;Evalyn&quot; &quot;Evelina&quot; &quot;Faye&quot; &quot;Huldah&quot; ## [649] &quot;Idell&quot; &quot;Inga&quot; &quot;Irena&quot; &quot;Jewell&quot; &quot;Kattie&quot; &quot;Lavenia&quot; ## [655] &quot;Leslie&quot; &quot;Lovina&quot; &quot;Lulie&quot; &quot;Magnolia&quot; &quot;Margeret&quot; &quot;Margery&quot; ## [661] &quot;Media&quot; &quot;Millicent&quot; &quot;Nena&quot; &quot;Ocie&quot; &quot;Orilla&quot; &quot;Osie&quot; ## [667] &quot;Pansy&quot; &quot;Ray&quot; &quot;Rosia&quot; &quot;Rowena&quot; &quot;Shirley&quot; &quot;Tabitha&quot; ## [673] &quot;Thomas&quot; &quot;Verdie&quot; &quot;Walter&quot; &quot;Zetta&quot; &quot;Zoa&quot; &quot;Zona&quot; ## [679] &quot;Albertina&quot; &quot;Albina&quot; &quot;Alyce&quot; &quot;Amie&quot; &quot;Angela&quot; &quot;Annis&quot; ## [685] &quot;Carol&quot; &quot;Carra&quot; &quot;Clarence&quot; &quot;Clarinda&quot; &quot;Delphia&quot; &quot;Dillie&quot; ## [691] &quot;Doshie&quot; &quot;Drucilla&quot; &quot;Etna&quot; &quot;Eugenie&quot; &quot;Eulalia&quot; &quot;Eve&quot; ## [697] &quot;Felicia&quot; &quot;Florance&quot; &quot;Fronie&quot; &quot;Geraldine&quot; &quot;Gina&quot; &quot;Glenna&quot; ## [703] &quot;Grayce&quot; &quot;Hedwig&quot; &quot;Jessica&quot; &quot;Jossie&quot; &quot;Katheryn&quot; &quot;Katy&quot; ## [709] &quot;Lea&quot; &quot;Leanna&quot; &quot;Leitha&quot; &quot;Leone&quot; &quot;Lidie&quot; &quot;Loma&quot; ## [715] &quot;Lular&quot; &quot;Magdalen&quot; &quot;Maymie&quot; &quot;Minervia&quot; &quot;Muriel&quot; &quot;Neppie&quot; ## [721] &quot;Olie&quot; &quot;Onie&quot; &quot;Osa&quot; &quot;Otelia&quot; &quot;Paralee&quot; &quot;Patience&quot; ## [727] &quot;Rella&quot; &quot;Rillie&quot; &quot;Rosanna&quot; &quot;Theo&quot; &quot;Tilda&quot; &quot;Tishie&quot; ## [733] &quot;Tressa&quot; &quot;Viva&quot; &quot;Yetta&quot; &quot;Zena&quot; &quot;Zola&quot; &quot;Abby&quot; ## [739] &quot;Aileen&quot; &quot;Alba&quot; &quot;Alda&quot; &quot;Alla&quot; &quot;Alverta&quot; &quot;Ara&quot; ## [745] &quot;Ardelia&quot; &quot;Ardella&quot; &quot;Arrie&quot; &quot;Arvilla&quot; &quot;Augustine&quot; &quot;Aurora&quot; ## [751] &quot;Bama&quot; &quot;Bena&quot; &quot;Byrd&quot; &quot;Calla&quot; &quot;Camilla&quot; &quot;Carey&quot; ## [757] &quot;Carlotta&quot; &quot;Celestia&quot; &quot;Cherry&quot; &quot;Cinda&quot; &quot;Classie&quot; &quot;Claudine&quot; ## [763] &quot;Clemie&quot; &quot;Clifford&quot; &quot;Clyda&quot; &quot;Creola&quot; &quot;Debbie&quot; &quot;Dee&quot; ## [769] &quot;Dinah&quot; &quot;Doshia&quot; &quot;Ednah&quot; &quot;Edyth&quot; &quot;Eleanora&quot; &quot;Electa&quot; ## [775] &quot;Eola&quot; &quot;Erie&quot; &quot;Eudora&quot; &quot;Euphemia&quot; &quot;Evalena&quot; &quot;Evaline&quot; ## [781] &quot;Faith&quot; &quot;Fidelia&quot; &quot;Freddie&quot; &quot;Golda&quot; &quot;Harry&quot; &quot;Helma&quot; ## [787] &quot;Hermine&quot; &quot;Hessie&quot; &quot;Ivah&quot; &quot;Janette&quot; &quot;Jennette&quot; &quot;Joella&quot; ## [793] &quot;Kathryne&quot; &quot;Lacy&quot; &quot;Lanie&quot; &quot;Lauretta&quot; &quot;Leana&quot; &quot;Leatha&quot; ## [799] &quot;Leo&quot; &quot;Liller&quot; &quot;Lillis&quot; &quot;Louetta&quot; &quot;Madie&quot; &quot;Mai&quot; ## [805] &quot;Martina&quot; &quot;Maryann&quot; &quot;Melva&quot; &quot;Mena&quot; &quot;Mercedes&quot; &quot;Merle&quot; ## [811] &quot;Mima&quot; &quot;Minda&quot; &quot;Monica&quot; &quot;Nealie&quot; &quot;Netta&quot; &quot;Nolia&quot; ## [817] &quot;Nonie&quot; &quot;Odelia&quot; &quot;Ottilie&quot; &quot;Phyllis&quot; &quot;Robbie&quot; &quot;Sabina&quot; ## [823] &quot;Sada&quot; &quot;Sammie&quot; &quot;Suzanne&quot; &quot;Sybilla&quot; &quot;Thea&quot; &quot;Tressie&quot; ## [829] &quot;Vallie&quot; &quot;Venie&quot; &quot;Viney&quot; &quot;Wilhelmine&quot; &quot;Winona&quot; &quot;Zelda&quot; ## [835] &quot;Zilpha&quot; &quot;Adelle&quot; &quot;Adina&quot; &quot;Adrienne&quot; &quot;Albertine&quot; &quot;Alys&quot; ## [841] &quot;Ana&quot; &quot;Araminta&quot; &quot;Arthur&quot; &quot;Birtha&quot; &quot;Bulah&quot; &quot;Caddie&quot; ## [847] &quot;Celie&quot; &quot;Charlotta&quot; &quot;Clair&quot; &quot;Concepcion&quot; &quot;Cordella&quot; &quot;Corrine&quot; ## [853] &quot;Delila&quot; &quot;Delphine&quot; &quot;Dosha&quot; &quot;Edgar&quot; &quot;Elaine&quot; &quot;Elisa&quot; ## [859] &quot;Ellar&quot; &quot;Elmire&quot; &quot;Elvina&quot; &quot;Ena&quot; &quot;Estie&quot; &quot;Etter&quot; ## [865] &quot;Fronnie&quot; &quot;Genie&quot; &quot;Georgina&quot; &quot;Glenn&quot; &quot;Gracia&quot; &quot;Guadalupe&quot; ## [871] &quot;Gwendolyn&quot; &quot;Hassie&quot; &quot;Honora&quot; &quot;Icy&quot; &quot;Isa&quot; &quot;Isadora&quot; ## [877] &quot;Jesse&quot; &quot;Jewel&quot; &quot;Joe&quot; &quot;Johannah&quot; &quot;Juana&quot; &quot;Judith&quot; ## [883] &quot;Judy&quot; &quot;Junie&quot; &quot;Lavonia&quot; &quot;Lella&quot; &quot;Lemma&quot; &quot;Letty&quot; ## [889] &quot;Linna&quot; &quot;Littie&quot; &quot;Lollie&quot; &quot;Lorene&quot; &quot;Louis&quot; &quot;Love&quot; ## [895] &quot;Lovisa&quot; &quot;Lucina&quot; &quot;Lynn&quot; &quot;Madora&quot; &quot;Mahalia&quot; &quot;Manervia&quot; ## [901] &quot;Manuela&quot; &quot;Margarett&quot; &quot;Margaretta&quot; &quot;Margarita&quot; &quot;Marilla&quot; &quot;Mignon&quot; ## [907] &quot;Mozella&quot; &quot;Natalie&quot; &quot;Nelia&quot; &quot;Nolie&quot; &quot;Omie&quot; &quot;Opal&quot; ## [913] &quot;Ossie&quot; &quot;Ottie&quot; &quot;Ottilia&quot; &quot;Parthenia&quot; &quot;Penelope&quot; &quot;Pinkey&quot; ## [919] &quot;Pollie&quot; &quot;Rennie&quot; &quot;Reta&quot; &quot;Roena&quot; &quot;Rosalee&quot; &quot;Roseanna&quot; ## [925] &quot;Ruthie&quot; &quot;Sabra&quot; &quot;Sannie&quot; &quot;Selena&quot; &quot;Sibyl&quot; &quot;Tella&quot; ## [931] &quot;Tempie&quot; &quot;Tennessee&quot; &quot;Teressa&quot; &quot;Texas&quot; &quot;Theda&quot; &quot;Thelma&quot; ## [937] &quot;Thursa&quot; &quot;Ula&quot; &quot;Vannie&quot; &quot;Verona&quot; &quot;Vertie&quot; &quot;Wilma&quot; ## [943] &quot;John&quot; &quot;William&quot; &quot;James&quot; &quot;Charles&quot; &quot;George&quot; &quot;Frank&quot; ## [949] &quot;Joseph&quot; &quot;Thomas&quot; &quot;Henry&quot; &quot;Robert&quot; &quot;Edward&quot; &quot;Harry&quot; ## [955] &quot;Walter&quot; &quot;Arthur&quot; &quot;Fred&quot; &quot;Albert&quot; &quot;Samuel&quot; &quot;David&quot; ## [961] &quot;Louis&quot; &quot;Joe&quot; &quot;Charlie&quot; &quot;Clarence&quot; &quot;Richard&quot; &quot;Andrew&quot; ## [967] &quot;Daniel&quot; &quot;Ernest&quot; &quot;Will&quot; &quot;Jesse&quot; &quot;Oscar&quot; &quot;Lewis&quot; ## [973] &quot;Peter&quot; &quot;Benjamin&quot; &quot;Frederick&quot; &quot;Willie&quot; &quot;Alfred&quot; &quot;Sam&quot; ## [979] &quot;Roy&quot; &quot;Herbert&quot; &quot;Jacob&quot; &quot;Tom&quot; &quot;Elmer&quot; &quot;Carl&quot; ## [985] &quot;Lee&quot; &quot;Howard&quot; &quot;Martin&quot; &quot;Michael&quot; &quot;Bert&quot; &quot;Herman&quot; ## [991] &quot;Jim&quot; &quot;Francis&quot; &quot;Harvey&quot; &quot;Earl&quot; &quot;Eugene&quot; &quot;Ralph&quot; ## [997] &quot;Ed&quot; &quot;Claude&quot; &quot;Edwin&quot; &quot;Ben&quot; ## [ reached getOption(&quot;max.print&quot;) -- omitted 1923665 entries ] Let’s use str_detect() to find all of the names that include a ‘sh’ sound: As you see, str_detect() runs as a boolean operator, in that it ascribes a TRUE or FALSE value for each entry in the column, based on our conditional statement: is there a ‘sh’ in the character string? Let’s combine our previous experience with ggplot to write a long, complicated set of code that will visualize the most popular names starting in ‘Sh’ for women born in 1938: babynames %&gt;% filter(str_detect(name, &quot;Sh&quot;) &amp; sex==&quot;F&quot; &amp; year == 1938) %&gt;% arrange(desc(prop)) %&gt;% head(20) %&gt;% ggplot(aes(reorder(name,prop),prop, fill = name)) + geom_col() + coord_flip() Let’s fancy that up a bit, by calculating a ‘percentage’ of use of that name per year / per gender: babynames %&gt;% filter(str_detect(name, &quot;Sh&quot;) &amp; sex==&quot;F&quot; &amp; year == 1938) %&gt;% arrange(desc(prop)) %&gt;% head(20) %&gt;% mutate(percent = (prop * 100)) %&gt;% ggplot(aes(reorder(name,percent),percent, fill = name)) + geom_col() + coord_flip() "],["how-many-z-names-since-2000.html", "Chapter 3 how many ‘z’ names since 2000?", " Chapter 3 how many ‘z’ names since 2000? babynames %&gt;% filter(year &gt; 2000 &amp; str_detect(name, &quot;Z&quot;)) %&gt;% arrange(desc(prop)) ## # A tibble: 13,018 × 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2001 M Zachary 18186 0.00880 ## 2 2002 M Zachary 16622 0.00805 ## 3 2003 M Zachary 15539 0.00740 ## 4 2004 M Zachary 13711 0.00649 ## 5 2005 M Zachary 12283 0.00578 ## 6 2006 M Zachary 11005 0.00502 ## 7 2007 M Zachary 10212 0.00461 ## 8 2008 M Zachary 9226 0.00424 ## 9 2012 F Zoey 7466 0.00386 ## 10 2009 M Zachary 8078 0.00381 ## # … with 13,008 more rows Why did R only pull out the names starting with Z? Because we capitalized it. How do we get both? babynames %&gt;% mutate(Z = str_count(babynames$name, &quot;[zZ]&quot;)) %&gt;% arrange(desc(prop)) ## # A tibble: 1,924,665 × 6 ## year sex name n prop Z ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1880 M John 9655 0.0815 0 ## 2 1881 M John 8769 0.0810 0 ## 3 1880 M William 9532 0.0805 0 ## 4 1883 M John 8894 0.0791 0 ## 5 1881 M William 8524 0.0787 0 ## 6 1882 M John 9557 0.0783 0 ## 7 1884 M John 9388 0.0765 0 ## 8 1882 M William 9298 0.0762 0 ## 9 1886 M John 9026 0.0758 0 ## 10 1885 M John 8756 0.0755 0 ## # … with 1,924,655 more rows Instead of arranging our data by name popularity, let’s look at the names with the most z’s in them: babynames %&gt;% mutate(Z = str_count(babynames$name, &quot;[zZ]&quot;)) %&gt;% arrange(desc(Z)) ## # A tibble: 1,924,665 × 6 ## year sex name n prop Z ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2010 M Zzyzx 5 0.00000244 3 ## 2 1880 F Lizzie 388 0.00398 2 ## 3 1880 F Kizzie 13 0.000133 2 ## 4 1881 F Lizzie 396 0.00401 2 ## 5 1881 F Kizzie 9 0.0000910 2 ## 6 1882 F Lizzie 495 0.00428 2 ## 7 1882 F Kizzie 9 0.0000778 2 ## 8 1882 F Dezzie 5 0.0000432 2 ## 9 1883 F Lizzie 496 0.00413 2 ## 10 1883 F Kizzie 14 0.000117 2 ## # … with 1,924,655 more rows What if, instead of specifying a particular letter, we just wanted to count the most frequent first letters in names? babynames %&gt;% mutate(first_letter = substr(name, 1,1)) -&gt; baby_letters Let’s plot that: baby_letters %&gt;% count(first_letter, sort = TRUE) %&gt;% ggplot(aes(reorder(first_letter, n),n)) + geom_col() + coord_flip() We can also use stringr to calculate the length of all of our strings. What is the frequency of the shortest and longest names? babynames %&gt;% mutate(length = str_length(name)) -&gt; babynames_length 3.0.1 Average name length over time Now, if we want to see the average length of a names over time, the code gets a little mroe advanced - note the mean function we haven’t used like this before: babynames_length %&gt;% group_by(year) %&gt;% summarise_at(vars(length), funs(mean(.))) %&gt;% ggplot(aes(year, length)) + geom_line() ## Warning: `funs()` was deprecated in dplyr 0.8.0. ## Please use a list of either functions or lambdas: ## ## # Simple named list: ## list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: ## tibble::lst(mean, median) ## ## # Using lambdas ## list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. The results are impressive. Let’s split them up by Sex: babynames_length %&gt;% group_by(year, sex) %&gt;% summarise_at(vars(length), funs(mean(.))) %&gt;% ggplot(aes(year, length, color = sex)) + geom_line() 3.0.2 Common issue: (example: most common 3-letter names) As mentioned in the last Chapter, summarise() is confusing. In the case of babynames, you’ll know to use it when you keep getting the same results over and over, and you want to group those names together. Let’s take a look at this issue by calculating the most common 3-letter names: babynames_length %&gt;% filter(length == 3) %&gt;% arrange(desc(prop)) ## # A tibble: 41,274 × 6 ## year sex name n prop length ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1975 F Amy 32252 0.0207 3 ## 2 1976 F Amy 31341 0.0199 3 ## 3 1974 F Amy 29564 0.0189 3 ## 4 1973 F Amy 26964 0.0174 3 ## 5 1977 F Amy 26731 0.0163 3 ## 6 1972 F Amy 25873 0.0160 3 ## 7 1880 F Ida 1472 0.0151 3 ## 8 1971 F Amy 26238 0.0150 3 ## 9 1881 F Ida 1439 0.0146 3 ## 10 1882 F Ida 1673 0.0145 3 ## # … with 41,264 more rows We get a lot of repeated names. Time to summarize! babynames_length %&gt;% filter(length == 3) %&gt;% group_by(name) %&gt;% summarise(total = sum(n) ) %&gt;% arrange(desc(total)) ## # A tibble: 970 × 2 ## name total ## &lt;chr&gt; &lt;int&gt; ## 1 Amy 692096 ## 2 Ann 469710 ## 3 Joe 462099 ## 4 Roy 407020 ## 5 Lee 292891 ## 6 Eva 263741 ## 7 Ava 251052 ## 8 Ian 222950 ## 9 Mia 216774 ## 10 Kim 214365 ## # … with 960 more rows Let’s try that again, with 2-letter names: babynames_length %&gt;% filter(length == 2) %&gt;% group_by(name) %&gt;% summarize(total = sum(n)) %&gt;% arrange(desc(total)) ## # A tibble: 149 × 2 ## name total ## &lt;chr&gt; &lt;int&gt; ## 1 Jo 180579 ## 2 Ty 45278 ## 3 Ed 26330 ## 4 Al 17221 ## 5 Bo 10856 ## 6 Lu 4013 ## 7 Cy 3418 ## 8 Wm 2737 ## 9 Kc 2585 ## 10 An 2048 ## # … with 139 more rows What is the longest name? babynames_length %&gt;% arrange(desc(length)) ## # A tibble: 1,924,665 × 6 ## year sex name n prop length ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1978 M Christophermich 5 0.00000293 15 ## 2 1979 M Johnchristopher 5 0.00000279 15 ## 3 1980 M Christophermich 7 0.00000377 15 ## 4 1980 M Christopherjohn 5 0.0000027 15 ## 5 1981 F Mariadelrosario 5 0.0000028 15 ## 6 1981 M Christopherjohn 5 0.00000268 15 ## 7 1982 F Mariadelosangel 6 0.00000331 15 ## 8 1982 M Christopherjohn 6 0.00000318 15 ## 9 1982 M Christophermich 5 0.00000265 15 ## 10 1983 M Christopherjohn 8 0.00000429 15 ## # … with 1,924,655 more rows How many 15 letter names are there? babynames_length %&gt;% filter(length == 15) %&gt;% count(name, sort = TRUE) ## # A tibble: 34 × 2 ## name n ## &lt;chr&gt; &lt;int&gt; ## 1 Christopherjohn 19 ## 2 Johnchristopher 17 ## 3 Christopherjame 16 ## 4 Franciscojavier 16 ## 5 Christophermich 8 ## 6 Ryanchristopher 7 ## 7 Christianjoseph 4 ## 8 Christopherjose 4 ## 9 Jonathanmichael 4 ## 10 Mariadelosangel 4 ## # … with 24 more rows Let’s plot those names: babynames %&gt;% filter(name %in% c(&quot;Christopherjohn&quot;,&quot;Johnchristopher&quot;,&quot;Christopherjame&quot;,&quot;Franciscojavier&quot;, &quot;Christophermich&quot;, &quot;Ryanchristopher&quot;,&quot;Christianjoseph&quot;, &quot;Christopherjose&quot;, &quot;Jonathanmichael&quot;, &quot;Mariadelosangel&quot; )) %&gt;% ggplot(aes(year, prop, color = name)) + geom_line() By the look of these names, it’s clear that most of them are actually longer than 15 characters - but 15 characters is the cut-off point for the column. Thus, we cannot accurately estimate the most common 15-letter names. Along similar lines, an analysis of the methodology behind babynames shows that only names that have at least 5 instances in a given year are recorded. So it’d be similarly futile for us to attempt to measure the rarest names, as they are excluded in the database. (It also helps clarify why some rarer names seem to ‘disappear’ in certain years.) OK, what else can stringr do? How about the average number of vowels per name? str_count(babynames$name, &quot;[aeiou]&quot;) ## [1] 1 1 1 3 3 3 1 2 2 2 2 2 1 3 2 2 3 3 2 3 3 2 3 3 3 3 3 1 3 2 4 3 1 3 2 3 4 1 2 1 1 ## [42] 2 2 1 1 3 2 2 3 4 2 2 4 1 3 2 1 3 2 2 1 1 2 3 3 2 3 2 3 2 2 1 3 3 4 3 2 2 2 2 3 1 ## [83] 2 4 2 2 3 3 2 2 3 3 1 3 2 3 2 2 4 1 3 2 1 1 3 4 2 0 2 2 2 3 3 1 4 3 2 3 3 1 2 0 3 ## [124] 3 2 3 3 3 1 4 3 2 1 2 2 1 3 3 2 3 1 2 3 2 3 3 4 4 1 3 1 3 3 4 3 3 2 1 3 3 2 2 2 3 ## [165] 3 1 1 2 3 1 2 4 2 2 2 2 3 2 2 3 3 3 1 1 3 4 3 3 2 2 3 1 3 3 3 3 2 3 2 2 3 5 2 4 3 ## [206] 2 4 3 3 2 2 2 3 3 3 1 3 3 2 2 2 3 4 5 2 4 1 3 1 3 2 2 4 1 3 3 4 2 3 2 1 3 3 2 1 3 ## [247] 4 3 3 3 4 3 2 2 3 5 2 3 2 4 2 2 3 2 2 3 4 4 1 3 3 3 0 3 1 3 2 1 3 2 2 3 2 1 1 3 3 ## [288] 2 1 2 3 4 1 2 2 4 1 3 2 2 3 2 3 2 2 3 3 2 2 1 3 3 3 4 3 3 3 3 2 3 2 2 2 2 3 1 2 3 ## [329] 2 3 3 2 3 1 2 4 2 3 4 2 2 1 2 2 3 4 4 3 3 3 3 2 4 3 1 2 3 3 3 4 4 3 1 3 3 3 2 3 1 ## [370] 1 3 3 2 3 4 4 1 4 3 3 2 3 4 2 2 2 2 3 2 3 2 3 5 3 2 3 2 2 3 1 2 1 2 1 3 2 2 2 3 2 ## [411] 3 3 2 1 3 3 2 3 3 2 2 3 2 2 4 1 4 4 3 3 1 4 2 2 2 3 3 1 2 3 5 3 3 2 2 1 2 4 1 1 1 ## [452] 3 2 3 3 1 3 2 4 3 3 3 2 2 4 3 2 1 2 4 3 3 1 2 3 4 2 1 1 1 3 3 3 4 3 3 1 2 3 2 2 3 ## [493] 4 3 4 3 3 4 3 2 2 2 3 2 3 2 3 2 3 3 2 2 3 3 2 2 2 2 1 2 3 2 3 1 2 3 1 1 2 1 1 2 3 ## [534] 3 3 3 3 3 5 3 3 4 3 2 2 2 1 4 2 1 3 3 3 3 3 3 1 1 3 2 2 2 3 4 4 3 2 3 3 2 4 4 2 3 ## [575] 2 5 3 1 3 2 2 3 1 3 3 1 2 3 2 3 1 2 3 2 1 2 3 3 1 1 1 1 2 3 2 3 3 5 1 3 2 2 3 3 4 ## [616] 4 2 2 1 1 3 4 4 3 2 2 3 2 2 2 3 1 3 4 3 3 3 3 2 3 2 3 2 0 1 3 2 2 1 1 2 2 3 4 3 3 ## [657] 3 4 3 2 3 3 2 2 2 2 1 1 3 3 2 3 2 3 2 2 2 2 3 2 1 2 2 1 2 2 3 3 3 3 3 3 1 4 4 1 4 ## [698] 3 3 4 2 2 2 2 3 3 2 1 2 3 3 3 3 2 2 3 3 4 3 3 2 2 1 3 4 4 2 3 3 2 2 3 2 2 2 2 2 0 ## [739] 3 1 1 1 2 1 3 2 2 2 4 3 2 2 0 2 3 2 3 4 1 2 3 4 3 2 1 3 3 2 2 3 1 0 4 2 2 2 3 4 3 ## [780] 3 2 4 3 2 1 2 3 3 1 3 3 3 2 1 3 4 3 3 2 2 2 4 3 2 3 2 2 2 3 2 2 2 3 4 2 3 3 3 3 1 ## [821] 3 3 2 3 3 2 2 3 3 3 2 4 3 2 2 2 2 3 3 0 1 3 1 2 2 3 3 3 2 4 3 3 3 3 2 1 3 2 1 2 2 ## [862] 1 2 1 3 3 4 1 3 5 2 3 3 0 1 3 2 2 2 3 3 2 1 3 4 2 2 1 2 3 3 3 3 2 3 3 0 3 4 4 4 3 ## [903] 4 4 3 2 3 4 3 3 2 1 2 2 3 4 4 2 3 3 2 3 4 4 3 2 3 3 1 2 3 4 3 2 2 2 2 1 3 3 3 2 1 ## [944] 3 2 2 3 1 2 2 1 2 1 1 2 1 1 1 3 2 3 2 3 3 2 1 3 1 1 2 1 2 2 3 3 3 1 1 1 2 2 1 1 1 ## [985] 2 2 2 3 1 2 1 2 2 1 3 1 0 3 1 1 ## [ reached getOption(&quot;max.print&quot;) -- omitted 1923665 entries ] That’s a lot of numbers. Let’s calculate a mean value instead: mean(str_count(babynames$name, &quot;[aeiou]&quot;)) ## [1] 2.420695 How about consonants? mean(str_count(babynames$name, &quot;[bcdfghjklmnpqrstvwxyz]&quot;)) ## [1] 2.752322 Example ideas for further exploration: How many names contain ‘liz’ in them? babynames %&gt;% filter(str_detect(babynames$name, &quot;liz&quot;) ) %&gt;% count(name, sort = TRUE) %&gt;% head(20) %&gt;% ggplot(aes(reorder(name, n),n)) + geom_col() + coord_flip() Case Study: Born Without A (Proper) Name There are a number of names in the database that are totally anonymous. When, and why? babynames %&gt;% filter(name %in% c(&quot;Unknown&quot;, &quot;Unnamed&quot;, &quot;Infant&quot;, &quot;Infantof&quot;, &quot;Notnamed&quot;, &quot;Baby&quot;)) %&gt;% ggplot(aes(year, prop, color = name)) + geom_line() + facet_wrap(~sex) Let’s compare this to the number of unique names per year: babynames %&gt;% group_by(year) %&gt;% summarize(annual = n_distinct(name)) %&gt;% ggplot(aes(year, annual )) + geom_line() Babynames also includes a data set called births, that simply lists out the total number of births per year: data(births) ggplot(births, aes(year, births)) + geom_line() Why are these last two graphs different? Because the first is counting names, the second is counting births. And most babies have names that are shared with other babies, especially in the same year. "],["network-analysis.html", "Chapter 4 Network Analysis", " Chapter 4 Network Analysis "],["geo-spatial-analysis-and-visualizations.html", "Chapter 5 Geo-Spatial Analysis and Visualizations", " Chapter 5 Geo-Spatial Analysis and Visualizations "],["publishing.html", "Chapter 6 Publishing", " Chapter 6 Publishing "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
